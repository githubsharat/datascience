{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4d5db17",
   "metadata": {},
   "source": [
    "1. **K-means for given centroids**:\n",
    "   \n",
    "   a) **Centroids: 15, 32**:\n",
    "      - Clusters formed:\n",
    "        1. 5, 10, 15 (Close to 15)\n",
    "        2. 20, 25, 30, 35 (Close to 32)\n",
    "   \n",
    "   b) **Centroids: 12, 30**:\n",
    "      - Clusters formed:\n",
    "        1. 5, 10 (Close to 12)\n",
    "        2. 15, 20, 25, 30, 35 (Close to 30)\n",
    "   \n",
    "   c) **SSE for Centroids: 15, 32**:\n",
    "      SSE = (5-15)² + (10-15)² + (20-32)² + (25-32)² + (30-32)² + (35-32)² = 170\n",
    "\n",
    "   d) **SSE for Centroids: 12, 30**:\n",
    "      SSE = (5-12)² + (10-12)² + (15-30)² + (20-30)² + (25-30)² + (35-30)² = 335\n",
    "   \n",
    "2. **Market Basket Analysis**: Uses association analysis concepts to find frequent itemsets and determine which items are bought together frequently. It aids retailers in placement, promotion, and recommendation.\n",
    "\n",
    "3. **Apriori Algorithm Example**: \n",
    "   Given transactions:\n",
    "   - T1: Bread, Milk\n",
    "   - T2: Bread, Diaper, Beer, Eggs\n",
    "   - T3: Milk, Diaper, Beer, Coke\n",
    "   - T4: Bread, Milk, Diaper, Beer\n",
    "   - T5: Bread, Milk, Diaper, Coke\n",
    "   Using Apriori, one can find that {Bread, Milk} is a frequent itemset.\n",
    "\n",
    "4. **Distance in Hierarchical Clustering**: Typically, the distance between clusters can be measured using single link (minimum pairwise distance), complete link (maximum pairwise distance), or average link (average pairwise distance). When a certain stopping criterion like a distance threshold or a desired number of clusters is reached, iterations stop.\n",
    "\n",
    "5. **Recompute Cluster Centroids in k-means**: The centroid of a cluster is recalculated as the mean of all data points assigned to that cluster.\n",
    "\n",
    "6. **Determining Number of Clusters**: The Elbow Method is commonly used where the SSE is plotted for a range of cluster numbers. The \"elbow\" of the curve represents an optimal number for clustering.\n",
    "\n",
    "7. **K-means Advantages and Disadvantages**:\n",
    "   - Advantages: Simple, widely used, scalable.\n",
    "   - Disadvantages: Sensitive to initial centroids, might converge to local optima, requires the number of clusters to be specified.\n",
    "\n",
    "8. **Principle of Clustering**:\n",
    "   Imagine a scatter plot with data points spread across. Clustering will group these data points based on their similarity or proximity into distinct clusters.\n",
    "\n",
    "9. **K-means with given clusters**:\n",
    "   New centroids:\n",
    "   - C1: Mean of (2,2), (4,4), (6,6) = (4,4)\n",
    "   - C2: Mean of (0,4), (4,0), (0,4) = (1.33, 2.67)\n",
    "   - C3: Mean of (5,5), (9,9) = (7,7)\n",
    "   SSE for new clustering would be the sum of squared distances from all points to their respective centroids.\n",
    "\n",
    "10. **Software Project Clustering**:\n",
    "   After using k-means to find the 5 clusters for the 20 defect data points, you'd have centroids for each cluster. For every new defect, compute its distance to each of these centroids and assign it to the closest cluster. This way, defects are categorized into one of the existing defect forms. A scatter plot can visually represent the clusters, with the centroids highlighted and new defects placed closest to their assigned cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2895f5bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
